{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecommerce Analytics - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import pickle\n",
    "import numpy as np                                \n",
    "import pandas as pd \n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "import utils\n",
    "\n",
    "from sagemaker import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sagemaker-us-east-2-962225948309'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::560062611886:role/service-role/AmazonSageMaker-ExecutionRole-20190311T034175\n"
     ]
    }
   ],
   "source": [
    "# Define IAM role- this will be necessary when defining your model\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n"
     ]
    }
   ],
   "source": [
    "my_region = boto3.session.Session().region_name\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = pd.read_csv('./customer_reviews_dataset.csv')\n",
    "order_item = pd.read_csv('./order_items_dataset.csv')\n",
    "orders = pd.read_csv('./orders_dataset.csv')\n",
    "products = pd.read_csv('./products_dataset.csv')\n",
    "product_name_translate = pd.read_csv('./product_category_name_translation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = customer_review[['review_id','order_id','survey_score']].merge(order_item[['order_id','product_id']], how = 'left', on = 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(orders[['order_id','customer_id']], how = 'left', on = 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(products[['product_id', 'product_category_name']], how = 'left', on = 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(product_name_translate, how = 'left', on = 'product_category_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "data = data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Avg Survey Score per category per customer\n",
    "d1 = data[['customer_id', 'product_category_name_english', 'survey_score']]\n",
    "#d1 = d1.groupby(by = ['customer_id', 'product_category_name_english']).mean()\n",
    "#d1 = d1.reset_index()\n",
    "d1 = d1.rename(index=str, columns={\"product_category_name_english\": \"category\"})\n",
    "d1 = d1.groupby(['customer_id','category'])['survey_score'].mean().unstack(fill_value=0)\n",
    "d1 = d1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total purchases per customer per category\n",
    "d2 = data[['customer_id', 'product_category_name_english']]\n",
    "d2 = d2.groupby(by = ['customer_id', 'product_category_name_english']).size().reset_index(name='counts')\n",
    "d2 = d2.rename(index=str, columns={\"product_category_name_english\": \"category\"})\n",
    "d2 = d2.groupby(['customer_id','category'])['counts'].sum().unstack(fill_value=0)\n",
    "d2 = d2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge d1 and d2\n",
    "data = d1.merge(d2, how = 'left', on ='customer_id', suffixes=('_rate','_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data sizes\n",
      "(77804, 143) (19452, 143)\n"
     ]
    }
   ],
   "source": [
    "# Split into Train and Test (0.8,0.2)\n",
    "train_data_unscaled, test_data_unscaled = np.split(data.sample(frac=1, \n",
    "                                                   random_state=1729), \n",
    "                                                   [int(0.8 * len(data))])\n",
    "\n",
    "print (\"Train and test data sizes\")\n",
    "print (train_data_unscaled.shape, test_data_unscaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature column\n",
    "featureCols = list(data.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Scale data for KMeans\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data_unscaled[featureCols])\n",
    "train_data = pd.DataFrame(train_data, columns=featureCols)[featureCols]\n",
    "test_data = scaler.transform(test_data_unscaled[featureCols])\n",
    "test_data = pd.DataFrame(test_data, columns=featureCols)[featureCols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up KMeans Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_location   = 's3://{}/data'.format(bucket_name)\n",
    "#output_location = 's3://{}/output'.format(bucket_name)\n",
    "\n",
    "#print('training data will be uploaded to: {}'.format(data_location))\n",
    "#print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.m4.xlarge',\n",
    "                k=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: kmeans-2019-04-02-05-17-11-285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-02 05:17:11 Starting - Starting the training job...\n",
      "2019-04-02 05:17:12 Starting - Launching requested ML instances......\n",
      "2019-04-02 05:18:13 Starting - Preparing the instances for training...\n",
      "2019-04-02 05:18:59 Downloading - Downloading input data\n",
      "2019-04-02 05:18:59 Training - Downloading the training image....\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'142', u'k': u'5', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'142', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 WARNING 140415369017152] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Using default worker.\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Create Store: local\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] nvidia-smi took: 0.0251109600067 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'142', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] number of center slices 1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1554182385.224185, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1554182385.224126}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-04-02 05:19:45.236] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 72, \"num_examples\": 1, \"num_bytes\": 2980000}\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Iter 10: Short term msd 100.575257. Long term msd 103.138123\u001b[0m\n",
      "\u001b[31m[2019-04-02 05:19:45.616] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 379, \"num_examples\": 16, \"num_bytes\": 46371184}\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] processed a total of 77804 examples\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 77804, \"sum\": 77804.0, \"min\": 77804}, \"Total Batches Seen\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}, \"Total Records Seen\": {\"count\": 1, \"max\": 82804, \"sum\": 82804.0, \"min\": 82804}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 77804, \"sum\": 77804.0, \"min\": 77804}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1554182385.617583, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1554182385.236928}\n",
      "\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] #throughput_metric: host=algo-1, train throughput=204302.640019 records/second\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 WARNING 140415369017152] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] shrinking 50 centers into 5\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #0. Current mean square distance 36.062000\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #1. Current mean square distance 36.170124\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #2. Current mean square distance 36.240322\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #3. Current mean square distance 36.137856\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #4. Current mean square distance 36.116726\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #5. Current mean square distance 36.127193\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #6. Current mean square distance 35.927200\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #7. Current mean square distance 36.083523\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #8. Current mean square distance 36.001965\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] local kmeans attempt #9. Current mean square distance 36.131981\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] finished shrinking process. Mean Square Distance = 36\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] #quality_metric: host=algo-1, train msd <loss>=35.9272003174\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] compute all data-center distances: point norm took: 28.3934%, (0.111628 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] compute all data-center distances: inner product took: 15.8349%, (0.062254 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] predict compute msd took: 14.4297%, (0.056730 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] batch data loading with context took: 9.2678%, (0.036436 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] gradient: cluster center took: 8.5494%, (0.033612 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] gradient: cluster size  took: 8.3663%, (0.032892 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] collect from kv store took: 5.7111%, (0.022453 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] splitting centers key-value pair took: 4.7264%, (0.018582 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] update state and report convergance took: 1.9555%, (0.007688 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] gradient: one_hot took: 1.4032%, (0.005517 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] compute all data-center distances: center norm took: 1.1713%, (0.004605 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] predict minus dist took: 0.1018%, (0.000400 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] update set-up time took: 0.0893%, (0.000351 secs)\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] TOTAL took: 0.393147230148\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 177.98304557800293, \"sum\": 177.98304557800293, \"min\": 177.98304557800293}, \"initialize.time\": {\"count\": 1, \"max\": 46.180009841918945, \"sum\": 46.180009841918945, \"min\": 46.180009841918945}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.14495849609375, \"sum\": 0.14495849609375, \"min\": 0.14495849609375}, \"update.time\": {\"count\": 1, \"max\": 380.3679943084717, \"sum\": 380.3679943084717, \"min\": 380.3679943084717}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 2.009868621826172, \"sum\": 2.009868621826172, \"min\": 2.009868621826172}, \"_shrink.time\": {\"count\": 1, \"max\": 176.12910270690918, \"sum\": 176.12910270690918, \"min\": 176.12910270690918}}, \"EndTime\": 1554182385.798342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1554182385.16403}\n",
      "\u001b[0m\n",
      "\u001b[31m[04/02/2019 05:19:45 INFO 140415369017152] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 717.1158790588379, \"sum\": 717.1158790588379, \"min\": 717.1158790588379}, \"setuptime\": {\"count\": 1, \"max\": 29.082059860229492, \"sum\": 29.082059860229492, \"min\": 29.082059860229492}}, \"EndTime\": 1554182385.800548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1554182385.798482}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-04-02 05:19:55 Uploading - Uploading generated training model\n",
      "2019-04-02 05:19:55 Completed - Training job completed\n",
      "Billable seconds: 65\n"
     ]
    }
   ],
   "source": [
    "km_model = kmeans.fit(kmeans.record_set(train_data.values.astype('float32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy KMeans Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: kmeans-2019-04-02-05-20-23-134\n",
      "INFO:sagemaker:Creating endpoint with name kmeans-2019-04-02-05-17-11-285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Model to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = kmeans_predictor.predict(train_data.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = kmeans_predictor.predict(train_data.values.astype('float32'))\n",
    "test_result = kmeans_predictor.predict(test_data.values.astype('float32'))\n",
    "\n",
    "# Retrieve the closest cluster label and distance to cluster for each sample in training and testing set\n",
    "train_clusters = [[r.label['closest_cluster'].float32_tensor.values[0],r.label['distance_to_cluster'].float32_tensor.values[0]] for r in train_result]\n",
    "test_clusters = [[r.label['closest_cluster'].float32_tensor.values[0],r.label['distance_to_cluster'].float32_tensor.values[0]] for r in test_result]\n",
    "\n",
    "train_clusters = np.array(train_clusters)\n",
    "test_clusters = np.array(test_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Samples among Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster_counts = pd.DataFrame(train_clusters[:,0])[0].value_counts().sort_index()\n",
    "plt.bar(np.arange(len(train_cluster_counts)),train_cluster_counts)\n",
    "plt.title(\"Cluster Counts for Training Set\")\n",
    "plt.show()\n",
    "\n",
    "test_cluster_counts = pd.DataFrame(test_clusters[:,0])[0].value_counts().sort_index()\n",
    "plt.bar(np.arange(len(test_cluster_counts)),test_cluster_counts)\n",
    "plt.title(\"Cluster Counts for Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Train/Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate original training/testing dataframe with new column with assigned cluster\n",
    "train_with_clusters = train_data_unscaled[featureCols]\n",
    "test_with_clusters = test_data_unscaled[featureCols]\n",
    "\n",
    "train_pd = pd.DataFrame(train_with_clusters, columns=featureCols+[\"prediction\",\"distance\"])\n",
    "test_pd = pd.DataFrame(test_with_clusters, columns=featureCols+[\"prediction\",\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Assigned Cluster and Distance to Cluster for Sample Train Samples\")\n",
    "display(train_pd[:5])\n",
    "print (\"\\nAssigned Cluster and Distance to Cluster for Sample Test Samples\")\n",
    "display(test_pd[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing KMeans Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get location of model on S3\n",
    "model_key = 'analytics/output/' + kmeans_predictor.endpoint + \"/output/model.tar.gz\"\n",
    "print(model_key)\n",
    "\n",
    "# Retrieve tar.gz file from your bucket\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# Untar model file \n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')\n",
    "\n",
    "# Load KMeans Model Parameters\n",
    "kmeans_model_params = mx.ndarray.load('model_algo-1')\n",
    "\n",
    "# Cluster centroids\n",
    "cluster_centroids=pd.DataFrame(kmeans_model_params[0].asnumpy())\n",
    "cluster_centroids.columns = featureCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Cluster Centroids\\n\", cluster_centroids)\n",
    "cluster_centers_named = utils.pd_centers(featureCols, cluster_centroids.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
